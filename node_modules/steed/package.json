{
  "_args": [
    [
      {
        "raw": "steed@^1.0.0",
        "scope": null,
        "escapedName": "steed",
        "name": "steed",
        "rawSpec": "^1.0.0",
        "spec": ">=1.0.0 <2.0.0",
        "type": "range"
      },
      "/Users/chencc/work/WebstormProjects/node-mqtt/node_modules/mosca"
    ]
  ],
  "_from": "steed@>=1.0.0 <2.0.0",
  "_id": "steed@1.1.3",
  "_inCache": true,
  "_location": "/steed",
  "_nodeVersion": "4.2.4",
  "_npmOperationalInternal": {
    "host": "packages-12-west.internal.npmjs.com",
    "tmp": "tmp/steed-1.1.3.tgz_1458316014659_0.007901560747995973"
  },
  "_npmUser": {
    "name": "matteo.collina",
    "email": "hello@matteocollina.com"
  },
  "_npmVersion": "2.14.12",
  "_phantomChildren": {},
  "_requested": {
    "raw": "steed@^1.0.0",
    "scope": null,
    "escapedName": "steed",
    "name": "steed",
    "rawSpec": "^1.0.0",
    "spec": ">=1.0.0 <2.0.0",
    "type": "range"
  },
  "_requiredBy": [
    "/ascoltatori",
    "/mosca"
  ],
  "_resolved": "https://registry.npmjs.org/steed/-/steed-1.1.3.tgz",
  "_shasum": "f1525dd5adb12eb21bf74749537668d625b9abc5",
  "_shrinkwrap": null,
  "_spec": "steed@^1.0.0",
  "_where": "/Users/chencc/work/WebstormProjects/node-mqtt/node_modules/mosca",
  "author": {
    "name": "Matteo Collina",
    "email": "hello@matteocollina.com"
  },
  "bugs": {
    "url": "https://github.com/mcollina/steed/issues"
  },
  "dependencies": {
    "fastfall": "^1.5.0",
    "fastparallel": "^2.2.0",
    "fastq": "^1.3.0",
    "fastseries": "^1.7.0",
    "reusify": "^1.0.0"
  },
  "description": "horsepower for your modules",
  "devDependencies": {
    "coveralls": "^2.11.6",
    "fastbench": "^1.0.0",
    "istanbul": "^0.4.1",
    "neo-async": "^1.7.0",
    "standard": "^5.4.1",
    "tap-spec": "^4.1.0",
    "tape": "^4.2.2"
  },
  "directories": {},
  "dist": {
    "shasum": "f1525dd5adb12eb21bf74749537668d625b9abc5",
    "tarball": "https://registry.npmjs.org/steed/-/steed-1.1.3.tgz"
  },
  "gitHead": "1bf30bbb18f5d7dae683009a01b40dbbb6636a6e",
  "homepage": "https://github.com/mcollina/steed#readme",
  "keywords": [
    "control",
    "flow",
    "async",
    "series",
    "parallel"
  ],
  "license": "MIT",
  "main": "steed.js",
  "maintainers": [
    {
      "name": "matteo.collina",
      "email": "hello@matteocollina.com"
    }
  ],
  "name": "steed",
  "optionalDependencies": {},
  "readme": "![logo][logo-url]\n\n# steed\n\n[![npm version][npm-badge]][npm-url]\n[![Build Status][travis-badge]][travis-url]\n[![Coverage Status][coveralls-badge]][coveralls-url]\n[![Dependency Status][david-badge]][david-url]\n\nHorsepower for your modules.\n\n__Steed__ is an alternative to [async](http://npm.im/async) that is\n~50-100% faster. It is not currently on-par with async in term of features.\nPlease help us!\n\n* <a href=\"#install\">Installation</a>\n* <a href=\"#api\">API</a>\n* <a href=\"#caveats\">Caveats</a>\n* <a href=\"#why\">Why it is so fast?</a>\n* <a href=\"#acknowledgements\">Acknowledgements</a>\n* <a href=\"#licence\">Licence &amp; copyright</a>\n\n[![js-standard-style](https://raw.githubusercontent.com/feross/standard/master/badge.png)](https://github.com/feross/standard)\n\nWatch Matteo presenting Steed at Node.js Interactive 2015: https://www.youtube.com/watch?v=_0W_822Dijg.\n\n## Install\n\n`npm i steed --save`\n\n## API\n\n* <a href=\"#steed\"><code><b>steed()</b></code></a>\n* <a href=\"#parallel\"><code>steed#<b>parallel()</b></code></a>\n* <a href=\"#series\"><code>steed#<b>series()</b></code></a>\n* <a href=\"#waterfall\"><code>steed#<b>waterfall()</b></code></a>\n* <a href=\"#each\"><code>steed#<b>each()</b></code></a>\n* <a href=\"#eachSeries\"><code>steed#<b>eachSeries()</b></code></a>\n* <a href=\"#map\"><code>steed#<b>map()</b></code></a>\n* <a href=\"#mapSeries\"><code>steed#<b>mapSeries()</b></code></a>\n* <a href=\"#queue\"><code>steed#<b>queue()</b></code></a>\n\n-------------------------------------------------------\n<a name=\"steed\"></a>\n### steed()\n\nBuild an instance of steed, this step is not needed but welcomed for\ngreater performance. Each steed utility likes being used for the same\npurpose.\n\n-------------------------------------------------------\n<a name=\"parallel\"></a>\n### steed.parallel([that,] tasks[, done(err, results)])\n\nExecutes a series of tasks in parallel.\n\n`tasks` can either be an array of functions, or an object where each\nproperty is a function. `done` will be called with the results.\nThe `that` argument will set `this` for each task and `done` callback.\n\nUses [fastparallel](http://npm.im/fastparallel).\n\nExample:\n\n```js\nvar steed = require('steed')()\n// or\n// var steed = require('steed')\n\nsteed.parallel([\n  function a (cb){\n    cb(null, 'a');\n  },\n  function b (cb){\n    cb(null, 'b');\n  }\n], function(err, results){\n  // results is ['a', 'b']\n})\n\n\n// an example using an object instead of an array\nsteed.parallel({\n  a: function a1 (cb){\n    cb(null, 1)\n  },\n  b: function b1 (cb){\n    cb(null, 2)\n  }\n}, function(err, results) {\n  // results is  { a: 1, b: 2}\n})\n\n// an example using that parameter\n// preferred form for max speed\nfunction run (prefix, a, b, cb) {\n  steed.parallel(new State(prefix, a, b, cb), [aT, bT], doneT)\n}\n\n// can be optimized by V8 using an hidden class\nfunction State (prefix, a, b, cb) {\n  this.a = a\n  this.b = b\n  this.cb = cb\n  this.prefix = prefix\n}\n\n// because it is not a closure inside run()\n// v8 can optimize this function\nfunction aT (cb){\n  cb(null, this.a);\n}\n\n// because it is not a closure inside run()\n// v8 can optimize this function\nfunction bT (cb){\n  cb(null, this.b);\n}\n\n// because it is not a closure inside run()\n// v8 can optimize this function\nfunction doneT (err, results) {\n  if (results) {\n    results.unshift(this.prefix)\n    results = results.join(' ')\n  }\n  this.cb(err, results)\n}\n\nrun('my name is', 'matteo', 'collina', console.log)\n```\n\nBenchmark for doing 3 calls `setImmediate` 1 million times:\n\n* non-reusable `setImmediate`: 1781ms\n* `async.parallel`: 3484ms\n* `neoAsync.parallel`: 2162ms\n* `insync.parallel`: 10252ms\n* `items.parallel`: 3725ms\n* `parallelize`: 2928ms\n* `fastparallel` with results: 2139ms\n\nThese benchmarks where taken on node v4.1.0, on a MacBook\nPro Retina Mid 2014 (i7, 16GB of RAM).\n\n-------------------------------------------------------\n<a name=\"series\"></a>\n### steed.series([that,] tasks[, done(err, results)])\n\nExecutes a series of tasks in series.\n\n`tasks` can either be an array of functions, or an object where each\nproperty is a function. `done` will be called with the results.\nThe `that` argument will set `this` for each task and `done` callback.\n\nUses [fastseries](http://npm.im/fastseries).\n\nExample:\n\n```js\nvar steed = require('steed')()\n// or\n// var steed = require('steed')\n\nsteed.series([\n  function a (cb){\n    cb(null, 'a');\n  },\n  function b (cb){\n    cb(null, 'b');\n  }\n], function(err, results){\n  // results is ['a', 'b']\n})\n\n\n// an example using an object instead of an array\nsteed.series({\n  a: function a (cb){\n    cb(null, 1)\n  },\n  b: function b (cb){\n    cb(null, 2)\n  }\n}, function(err, results) {\n  // results is  { a: 1, b: 2}\n})\n\n// an example using that parameter\n// preferred form for max speed\nfunction run (prefix, a, b, cb) {\n  steed.series(new State(prefix, a, b, cb), [aT, bT], doneT)\n}\n\n// can be optimized by V8 using an hidden class\nfunction State (prefix, a, b, cb) {\n  this.a = a\n  this.b = b\n  this.cb = cb\n  this.prefix = prefix\n}\n\n// because it is not a closure inside run()\n// v8 can optimize this function\nfunction aT (cb){\n  cb(null, this.a);\n}\n\n// because it is not a closure inside run()\n// v8 can optimize this function\nfunction bT (cb){\n  cb(null, this.b);\n}\n\n// because it is not a closure inside run()\n// v8 can optimize this function\nfunction doneT (err, results) {\n  if (results) {\n    results.unshift(this.prefix)\n    results = results.join(' ')\n  }\n  this.cb(err, results)\n}\n\nrun('my name is', 'matteo', 'collina', console.log)\n```\n\nBenchmark for doing 3 calls `setImmediate` 1 million times:\n\n* non-reusable `setImmediate`: 3887ms\n* `async.series`: 5981ms\n* `neoAsync.series`: 4338ms\n* `fastseries` with results: 4096ms\n\nThese benchmarks where taken on node v4.2.2, on a MacBook\nPro Retina Mid 2014 (i7, 16GB of RAM).\n\n-------------------------------------------------------\n<a name=\"waterfall\"></a>\n### steed.waterfall(tasks[, done(err, ...)])\n\nRuns the functions in `tasks` in series, each passing their result to\nthe next task in the array. Quits early if any of the tasks errors.\n\nUses [fastfall](http://npm.im/fastfall).\n\nExample:\n\n```js\nvar steed = require('steed')()\n// or\n// var steed = require('steed')\n\nsteed.waterfall([\n  function a (cb) {\n    console.log('called a')\n    cb(null, 'a')\n  },\n  function b (a, cb) {\n    console.log('called b with:', a)\n    cb(null, 'a', 'b')\n  },\n  function c (a, b, cb) {\n    console.log('called c with:', a, b)\n    cb(null, 'a', 'b', 'c')\n  }], function result (err, a, b, c) {\n    console.log('result arguments', arguments)\n  })\n\n// preferred version for maximum speed\nfunction run (word, cb) {\n  steed.waterfall(new State(cb), [\n    aT, bT, cT,\n  ], cb)\n}\n\n// can be optimized by V8 using an hidden class\nfunction State (value) {\n  this.value = value\n}\n\n// because it is not a closure inside run()\n// v8 can optimize this function\nfunction aT (cb) {\n  console.log(this.value)\n  console.log('called a')\n  cb(null, 'a')\n}\n\n// because it is not a closure inside run()\n// v8 can optimize this function\nfunction bT (a, cb) {\n  console.log('called b with:', a)\n  cb(null, 'a', 'b')\n}\n\n// because it is not a closure inside run()\n// v8 can optimize this function\nfunction cT (a, b, cb) {\n  console.log('called c with:', a, b)\n  cb(null, 'a', 'b', 'c')\n}\n```\n\nBenchmark for doing 3 calls `setImmediate` 100 thousands times:\n\n* non-reusable setImmediate: 418ms\n* `async.waterfall`: 1174ms\n* `run-waterfall`: 1432ms\n* `insync.wasterfall`: 1174ms\n* `neo-async.wasterfall`: 469ms\n* `waterfallize`: 749ms\n* `fastfall`: 452ms\n\nThese benchmarks where taken on node v4.2.2, on a MacBook\nPro Retina Mid 2014 (i7, 16GB of RAM).\n\n-------------------------------------------------------\n<a name=\"each\"></a>\n### steed.each([that,] array, iterator(item, cb), [, done()])\n\nIterate over all elements of the given array asynchronosly and in\nparallel.\nCalls `iterator` with an item and a callback. Calls `done` when all have\nbeen processed.\n\nThe `that` argument will set `this` for each task and `done` callback.\n\n`each` does not handle errors, if you need errors, use [`map`](#map).\n\nUses [fastparallel](http://npm.im/fastparallel).\n\nExample:\n\n```js\nvar steed = require('steed')()\n// or\n// var steed = require('steed')\n\nvar input = [1, 2, 3]\nvar factor = 2\n\nsteed.each(input, function (num, cb) {\n  console.log(num * factor)\n  setImmediate(cb)\n}, function () {\n  console.log('done')\n})\n\n// preferred version for max speed\nfunction run (factor, args, cb) {\n  steed.each(new State(factor), work, cb)\n}\n\n// can be optimizied by V8 using an hidden class\nfunction State (factor) {\n  this.factor = factor\n}\n\n// because it is not a closure inside run()\n// v8 can optimize this function\nfunction work (num, cb) {\n  console.log(num * this.factor)\n  cb()\n}\n\nrun(factor, input, console.log)\n```\n\nBenchmark for doing 3 calls `setImmediate` 1 million times:\n\n* non-reusable `setImmediate`: 1781ms\n* `async.each`: 2621ms\n* `neoAsync.each`: 2156ms\n* `insync.parallel`: 10252ms\n* `insync.each`: 2397ms\n* `fastparallel` each: 1941ms\n\nThese benchmarks where taken on node v4.2.2, on a MacBook\nPro Retina Mid 2014 (i7, 16GB of RAM).\n\n-------------------------------------------------------\n<a name=\"eachSeries\"></a>\n### steed.eachSeries([that,] array, iterator(item, cb), [, done(err)])\n\nIterate over all elements of the given array asynchronously and in\nseries.\nCalls `iterator` with an item and a callback. Calls `done` when all have\nbeen processed.\n\nThe `that` argument will set `this` for each task and `done` callback.\n\n`eachSeries` does not handle errors, if you need errors, use [`mapSeries`](#mapSeries).\n\nUses [fastseries](http://npm.im/fastseries).\n\nExample:\n\n```js\nvar steed = require('steed')()\n// or\n// var steed = require('steed')\n\nvar input = [1, 2, 3]\nvar factor = 2\n\nsteed.eachSeries(input, function (num, cb) {\n  console.log(num * factor)\n  setImmediate(cb)\n}, function (err) {\n  console.log(err)\n})\n\n// preferred version for max speed\nfunction run (factor, args, cb) {\n  steed.eachSeries(new State(factor), work, cb)\n}\n\n// can be optimizied by V8 using an hidden class\nfunction State (factor) {\n  this.factor = factor\n}\n\n// because it is not a closure inside run()\n// v8 can optimize this function\nfunction work (num, cb) {\n  console.log(num * this.factor)\n  cb()\n}\n\nrun(factor, input, console.log)\n```\n\nBenchmark for doing 3 calls `setImmediate` 1 million times:\n\n* non-reusable `setImmediate`: 3887ms\n* `async.mapSeries`: 5540ms\n* `neoAsync.eachSeries`: 4195ms\n* `fastseries` each: 4168ms\n\nThese benchmarks where taken on node v4.2.2, on a MacBook\nPro Retina Mid 2014 (i7, 16GB of RAM).\n\n-------------------------------------------------------\n<a name=\"map\"></a>\n### steed.map([that,]Â array, iterator(item, cb), [, done(err, results)])\n\nPerforms a map operation over all elements of the given array asynchronously and in\nparallel. The result is an a array where all items have been replaced by\nthe result of `iterator`.\n\nThe `that` argument will set `this` for each task and `done` callback.\n\nCalls `iterator` with an item and a callback. Calls `done` when all have\nbeen processed.\n\nUses [fastparallel](http://npm.im/fastparallel).\n\nExample:\n\n```js\nvar steed = require('steed')()\n// or\n// var steed = require('steed')\n\nvar input = [1, 2, 3]\nvar factor = 2\n\nsteed.map(input, function (num, cb) {\n  setImmediate(cb, null, num * factor)\n}, function (err, results) {\n  if (err) { throw err }\n\n  console.log(results.reduce(sum))\n})\n\nfunction sum (acc, num) {\n  return acc + num\n}\n\n// preferred version for max speed\nfunction run (factor, args, cb) {\n  steed.map(new State(factor, cb), args, work, done)\n}\n\n// can be optimizied by V8 using an hidden class\nfunction State (factor, cb) {\n  this.factor = factor\n  this.cb = cb\n}\n\n// because it is not a closure inside run()\n// v8 can optimize this function\nfunction work (num, cb) {\n  setImmediate(cb, null, num * this.factor)\n}\n\nfunction done (err, results) {\n  results = results || []\n  this.cb(err, results.reduce(sum))\n}\n\nrun(2, [1, 2, 3], console.log)\n```\n\nBenchmark for doing 3 calls `setImmediate` 1 million times:\n\n* non-reusable `setImmediate`: 1781ms\n* `async.map`: 3054ms\n* `neoAsync.map`: 2080ms\n* `insync.map`: 9700ms\n* `fastparallel` map: 2102ms\n\nThese benchmarks where taken on node v4.2.2, on a MacBook\nPro Retina Mid 2014 (i7, 16GB of RAM).\n\n-------------------------------------------------------\n<a name=\"mapSeries\"></a>\n### steed.mapSeries([that,] array, iterator(item, cb), [, done(err, results)])\n\nPerforms a map operation over all elements of the given array asynchronosly and in\nseries. The result is an a array where all items have been replaced by\nthe result of `iterator`.\n\nCalls `iterator` with an item and a callback. Calls `done` when all have\nbeen processed.\n\nThe `that` argument will set `this` for each task and `done` callback.\n\nUses [fastseries](http://npm.im/fastseries).\n\nExample:\n\n```js\nvar steed = require('steed')()\n// or\n// var steed = require('steed')\n\nvar input = [1, 2, 3]\nvar factor = 2\n\nsteed.mapSeries(input, function (num, cb) {\n  setImmediate(cb, null, num * factor)\n}, function (err, results) {\n  if (err) { throw err }\n\n  console.log(results.reduce(sum))\n})\n\nfunction sum (acc, num) {\n  return acc + num\n}\n\n// preferred version for max speed\nfunction run (factor, args, cb) {\n  steed.mapSeries(new State(factor, cb), args, work, done)\n}\n\n// can be optimizied by V8 using an hidden class\nfunction State (factor, cb) {\n  this.factor = factor\n  this.cb = cb\n}\n\n// because it is not a closure inside run()\n// v8 can optimize this function\nfunction work (num, cb) {\n  setImmediate(cb, null, num * this.factor)\n}\n\nfunction done (err, results) {\n  results = results || []\n  this.cb(err, results.reduce(sum))\n}\n\nrun(2, [1, 2, 3], console.log)\n```\n\nBenchmark for doing 3 calls `setImmediate` 1 million times:\n\n* non-reusable `setImmediate`: 3887ms\n* `async.mapSeries`: 5540ms\n* `neoAsync.mapSeries`: 4237ms\n* `fastseries` map: 4032ms\n\nThese benchmarks where taken on node v4.2.2, on a MacBook\nPro Retina Mid 2014 (i7, 16GB of RAM).\n\n-------------------------------------------------------\n<a name=\"queue\"></a>\n### steed.queue(worker, concurrency)\n\nCreates a new queue. See [fastq](http://npm.im/fastq) for full API.\n\nArguments:\n\n* `worker`, worker function, it would be called with `that` as `this`,\n  if that is specified.\n* `concurrency`, number of concurrent tasks that could be executed in\n  parallel.\n\nExample:\n\n```js\nvar steed = require('steed')()\n// or\n// var steed = require('steed')\n\nvar queue = steed.queue(worker, 1)\n\nqueue.push(42, function (err, result) {\n  if (err) { throw err }\n  console.log('the result is', result)\n})\n\nfunction worker (arg, cb) {\n  cb(null, arg * 2)\n}\n```\n\nBenchmarks (1 million tasks):\n\n* setImmedidate: 1313ms\n* fastq: 1462ms\n* async.queue: 3989ms\n\nObtained on node 4.2.2, on a MacBook Pro 2014 (i7, 16GB of RAM).\n\n## Caveats\n\nThis library works by caching the latest used function, so that running a new parallel\ndoes not cause **any memory allocations**.\n\nThe `done` function will be called only once, even if more than one error happen.\n\n__Steed__ has no safety checks: you should be responsible to avoid sync\nfunctions and so on. Also arguments type checks are not included, so be\ncareful in what you pass.\n\n<a name=\"why\"></a>\n## Why it is so fast?\n\n1. This library is caching functions a lot. We invented a technique to\n   do so, and packaged it in a module: [reusify](http://npm.im/reusify).\n\n2. V8 optimizations: thanks to caching, the functions can be optimized by V8\n   (if they are optimizable, and we took great care of making them so).\n\n3. Don't use arrays if you just need a queue. A linked list implemented via\n   objects is much faster if you do not need to access elements in between.\n\n## Acknowledgements\n\nSteed is sponsored by [nearForm](http://nearform.com).\n\nThe steed logo was created, with thanks, by [Dean McDonnell](https://github.com/mcdonnelldean)\n\n## License\n\nMIT\n\n[logo-url]: https://raw.githubusercontent.com/mcollina/steed/master/assets/banner.png\n[npm-badge]: https://badge.fury.io/js/steed.svg\n[npm-url]: https://badge.fury.io/js/steed\n[travis-badge]: https://api.travis-ci.org/mcollina/steed.svg\n[travis-url]: https://travis-ci.org/mcollina/steed\n[coveralls-badge]:https://coveralls.io/repos/mcollina/steed/badge.svg?branch=master&service=github\n[coveralls-url]: https://coveralls.io/github/mcollina/steed?branch=master\n[david-badge]: https://david-dm.org/mcollina/steed.svg\n[david-url]: https://david-dm.org/mcollina/steed\n",
  "readmeFilename": "README.md",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/mcollina/steed.git"
  },
  "scripts": {
    "coverage": "istanbul cover tape test.js; cat coverage/lcov.info | coveralls",
    "test": "standard && tape test.js | tap-spec"
  },
  "version": "1.1.3"
}
